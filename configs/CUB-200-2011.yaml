# Dataset Configuration
dataset_config:
  dataset: "CUB-200-2011"
  num_workers: 64
  batch_size: 256

  # DATASET VARIABLES
  root_dir: ./data/CUB_200_2011
  sampling_percent: 1
  test_subsampling: 1
  weight_loss: True

intervention_config:
  competence_levels: [ 1, 0 ]
  intervention_freq: 1
  intervention_batch_size: 1024
  intervention_policies:
    - policy: "random"
      group_level: True
      use_prior: True  # This will make the random policy use the learnt IntCEM prior!!!
    - policy: "random"
      group_level: True
      use_prior: False
    - policy: "coop"
      group_level: True
      use_prior: False
    - policy: "behavioural_cloning"
      group_level: True
      use_prior: False
    - policy: "optimal_greedy"
      group_level: True
      use_prior: False
    - policy: "global_val_error"
      group_level: True
      use_prior: False
    - policy: "global_val_improvement"
      group_level: True
      use_prior: False
# Representation metrics
# Change to False if you want representation metrics to be included in the
# evaluation (may significantly increase experiment times)
skip_repr_evaluation: False
run_repr_avg_pred: True
run_cas: False
run_nis: True
run_ois: True

max_epochs: 80
top_k_accuracy: null
save_model: True
patience: 15
emb_size: 32
extra_dims: 0
concept_loss_weight_labeled: 1  # 1 is best
concept_loss_weight_unlabeled: 0.1  # 0.1 is best
learning_rate: 0.01
weight_decay: 0.000005
weight_loss: True
c_extractor_arch: resnet34
optimizer: sgd
bool: False
early_stopping_monitor: val_loss
early_stopping_mode: min
early_stopping_delta: 0.0
momentum: 0.9
sigmoidal_prob: False
training_intervention_prob: 0.25

labeled_ratio: 1

runs:
  - architecture: 'ConceptEmbeddingModel'
    run_name: "CEM"
    sigmoidal_prob: True
    training_intervention_prob: 0.25
    embedding_activation: "leakyrelu"